{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/Lora-Training-GUI/blob/main/lora_training_gui_v5_2420.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kohya SS GUI Based Ver 24.2.0\n",
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated [here](https://github.com/monsterhunters/Lora-Training-GUI.git)!**\n",
        "\n",
        "ðŸ–‹ **Author**: [kyawkaung](https://colab.research.google.com/github/monsterhunters/Lora-Training-GUI/blob/main/Lora_Training_GUI_V1_2411.ipynb)\n",
        "\n",
        "ðŸ˜Ž **Support the Project**:\n",
        "\n",
        "If you find this project useful, please consider supporting it:\n",
        "\n",
        "<a href=\"https://ko-fi.com/kyawkaung\" target=\"_blank\">\n",
        "    <img src=\"https://storage.ko-fi.com/cdn/kofi2.png?v=3\" alt=\"Buy Me a Coffee at ko-fi.com\" height=\"36\">\n",
        "</a>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "n1xJLxZ1YljF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Install ðŸš€\n",
        "#@markdown Kohya SS GUI by Codemaster\n",
        "mount_gdrive = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import os, subprocess, time, glob, zipfile, shutil\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "from urllib.parse import unquote\n",
        "from google.colab.output import eval_js\n",
        "import time\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  start_colab = int(time.time())-5\n",
        "\n",
        "start_install = int(time.time())\n",
        "\n",
        "print('Info - The whole process may take up to 10 min. So, please be patient...')\n",
        "\n",
        "def mountGdrive():\n",
        "    print('Mounting Gdrive')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if mount_gdrive:\n",
        "    mountGdrive()\n",
        "\n",
        "#print('Installing torch & xformers')\n",
        "#with capture.capture_output() as cap:\n",
        "#    !pip install -q torch==2.5.0+cu124 torchvision==0.20.0+cu124 --extra-index-url https://download.pytorch.org/whl/cu124\n",
        "#    !pip install -q xformers==0.0.28.post2\n",
        "\n",
        "print('Installing dependencies')\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    !git clone -b sd3-flux.1 https://github.com/bmaltais/kohya_ss.git\n",
        "    %cd /content/kohya_ss\n",
        "\n",
        "#MOD\n",
        "    #!pip install -q aiofiles==23.2.1 dadaptation==3.2 diffusers[torch]==0.25.0\n",
        "    #!pip install -q easygui==0.98.3 fairscale==0.4.13 ftfy==6.1.1 gradio==5.4.0\n",
        "    #!pip install -q invisible-watermark==0.2.0 lion-pytorch==0.0.6 lycoris_lora==3.1.0 omegaconf==2.3.0\n",
        "    #!pip install -q onnx==1.16.1 prodigyopt==1.0 open-clip-torch==2.20.0\n",
        "    #!pip install -q pytorch-lightning==1.9.0 schedulefree==1.2.7\n",
        "    #!pip install -q tk==0.1.0 voluptuous==0.13.1\n",
        "    #!pip install -q bitsandbytes==0.44.0 onnxruntime-gpu==1.19.2\n",
        "\n",
        "    !pip install -q accelerate==0.33.0 aiofiles==23.2.1 altair==4.2.2 dadaptation==3.2 diffusers[torch]==0.25.0\n",
        "    !pip install -q easygui==0.98.3 einops==0.7.0 fairscale==0.4.13 ftfy==6.1.1 gradio==5.4.0 huggingface-hub==0.25.2\n",
        "    !pip install -q imagesize==1.4.1 invisible-watermark==0.2.0 lion-pytorch==0.0.6 lycoris_lora==3.1.0 omegaconf==2.3.0\n",
        "    !pip install -q onnx==1.16.1 prodigyopt==1.0 protobuf==3.20.3 open-clip-torch==2.20.0 opencv-python==4.10.0.84\n",
        "    !pip install -q pytorch-lightning==1.9.0 rich>=13.7.1 safetensors==0.4.4 schedulefree==1.2.7 scipy==1.11.4\n",
        "    !pip install -q sentencepiece==0.2.0 timm==0.6.12 tk==0.1.0 toml==0.10.2 transformers==4.44.2 voluptuous==0.13.1 wandb==0.18.0\n",
        "    !pip install -q bitsandbytes==0.44.0 tensorboard tensorflow>=2.16.1 onnxruntime-gpu==1.19.2\n",
        "\n",
        "\n",
        "print('Optimizing')\n",
        "with capture.capture_output() as cap:\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    os.environ[\"TCMALLOC_AGGRESSIVE_DECOMMIT\"] = \"t\"\n",
        "    os.environ[\"LD_PRELOAD\"] = \"/content/libtcmalloc_minimal.so.4\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "print('Almost finish....')\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/kohya_ss\n",
        "    !git clone https://github.com/kohya-ss/sd-scripts.git\n",
        "    !wget https://raw.githubusercontent.com/monsterhunters/stablecode/master/cf.py\n",
        "    !python cf.py\n",
        "    !pip install -e ./sd-scripts\n",
        "\n",
        "\n",
        "install_time = timedelta(seconds=time.time()-start_install)\n",
        "print(\"\\rðŸš€ Finished unpacking. Took\",\"%02d:%02d:%02d âš¡\\n\" % (install_time.seconds / 3600, (install_time.seconds / 60) % 60, install_time.seconds % 60), end='', flush=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "i132kqRppIuu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract and Set lora name\n",
        "keyword = \"\"  # @param {\"type\":\"string\"}\n",
        "zip_file_path = \"\"  # @param {type:\"string\"}\n",
        "import json\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.system('wget https://raw.githubusercontent.com/monsterhunters/Lora-Training-GUI/refs/heads/main/lora2.config')\n",
        "# Define the function to update the JSON properties\n",
        "def update_json_properties(json_file_path, output_file_path):\n",
        "    # Get the current month\n",
        "    current_month = datetime.now().strftime('%m_%d')  # Example: '12_14'\n",
        "\n",
        "    # Load the JSON data\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Update the properties\n",
        "    data[\"output_dir\"] = f\"/content/drive/MyDrive/Lora_{current_month}/output_{current_month}\"\n",
        "    data[\"output_name\"] = str(keyword)\n",
        "    data[\"train_data_dir\"] = f\"/content/drive/MyDrive/Lora_{current_month}/img_{current_month}\"\n",
        "\n",
        "    # Write the updated JSON back to a new file\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "    return current_month\n",
        "\n",
        "# Example usage\n",
        "os.system('wget https://raw.githubusercontent.com/monsterhunters/Lora-Training-GUI/refs/heads/main/lora.config')\n",
        "input_json_path = 'lora.config'  # Replace with your input JSON file path\n",
        "output_json_path = 'presets/lora/lora.json'  # Replace with your desired output JSON file path\n",
        "\n",
        "# Update JSON properties and get the current month\n",
        "current_month = update_json_properties(input_json_path, output_json_path)\n",
        "\n",
        "# Define the extracted folder path\n",
        "extracted_folder_path = f\"/content/drive/MyDrive/Lora_{current_month}/img_{current_month}\"\n",
        "\n",
        "# Create a directory to extract the contents of the zip file\n",
        "os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "if zip_file_path:  # Only attempt extraction if a zip file is provided\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_folder_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fpbak-4S2Loq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Run ðŸš€\n",
        "colab_fix = True # @param {\"type\":\"boolean\"}\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "if colab_fix:\n",
        "    os.system('wget -O requirements_pytorch_windows.txt https://raw.githubusercontent.com/monsterhunters/Lora-Training-GUI/refs/heads/main/req_fix/requirements_pytorch_windows.txt')\n",
        "    os.system('wget -O requirements_linux.txt https://raw.githubusercontent.com/monsterhunters/Lora-Training-GUI/refs/heads/main/req_fix/requirements_linux.txt')\n",
        "\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    print(\"\\nUI finished loading, trying to launch (if it gets stuck here, it is having issues)\\n\")\n",
        "\n",
        "    p = subprocess.Popen([\"wex\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in p.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com \" in l:\n",
        "            print(\"This is the URL to access UI:\", l[l.find(\"http\"):], end='')\n",
        "\n",
        "# Start the iframe_thread function in a separate thread\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "\n",
        "# Run the kohya_gui.py script and redirect its output to both the terminal and a file\n",
        "with subprocess.Popen([\"python\", \"kohya_gui.py\", \"--headless\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True) as process:\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')  # Print output to terminal\n",
        "        with open('ss.log', 'a') as f:\n",
        "            f.write(line)  # Write output to file\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "A1hgUzxotiUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}